//////////////////////////////////////////////////////////////////////
// This file was automatically generated by CLIF to run under Python 3
// Version 0.3
//////////////////////////////////////////////////////////////////////
// source: /pykaldi/kaldi/rnnlm/rnnlm-core-training.clif

#include <Python.h>
#include "clif/python/ptr_util.h"
#include "clif/python/optional.h"
#include "clif/python/types.h"
#include "itf/options-itf-clifwrap.h"
#include "cudamatrix/cu-matrix-clifwrap.h"
#include "nnet3/nnet-nnet-clifwrap.h"
#include "rnnlm/rnnlm-example-clifwrap.h"
#include "rnnlm/rnnlm-example-utils-clifwrap.h"
#include "rnnlm-core-training-clifwrap.h"
#include "clif/python/stltypes.h"
#include "clif/python/slots.h"

namespace __rnnlm__core__training_clifwrap {
using namespace clif;

#define _0 py::postconv::PASS
#define _1 UnicodeFromBytes
#define _2 UnicodeFromBytes


namespace pyRnnlmCoreTrainerOptions {

struct wrapper {
  PyObject_HEAD
  ::clif::Instance<::kaldi::rnnlm::RnnlmCoreTrainerOptions> cpp;
};
static ::kaldi::rnnlm::RnnlmCoreTrainerOptions* ThisPtr(PyObject*);

static PyObject* get_print_interval(PyObject* self, void* xdata) {
  auto cpp = ThisPtr(self); if (!cpp) return nullptr;
  return Clif_PyObjFrom(cpp->print_interval, {});
}

static int set_print_interval(PyObject* self, PyObject* value, void* xdata) {
  if (value == nullptr) {
    PyErr_SetString(PyExc_TypeError, "Cannot delete the print_interval attribute");
    return -1;
  }
  auto cpp = ThisPtr(self); if (!cpp) return -1;
  if (Clif_PyObjAs(value, &cpp->print_interval)) return 0;
  PyObject* s = PyObject_Repr(value);
  PyErr_Format(PyExc_ValueError, "%s is not valid for print_interval:int", s? PyUnicode_AsUTF8(s): "input");
  Py_XDECREF(s);
  return -1;
}

static PyObject* get_momentum(PyObject* self, void* xdata) {
  auto cpp = ThisPtr(self); if (!cpp) return nullptr;
  return Clif_PyObjFrom(cpp->momentum, {});
}

static int set_momentum(PyObject* self, PyObject* value, void* xdata) {
  if (value == nullptr) {
    PyErr_SetString(PyExc_TypeError, "Cannot delete the momentum attribute");
    return -1;
  }
  auto cpp = ThisPtr(self); if (!cpp) return -1;
  if (Clif_PyObjAs(value, &cpp->momentum)) return 0;
  PyObject* s = PyObject_Repr(value);
  PyErr_Format(PyExc_ValueError, "%s is not valid for momentum:float", s? PyUnicode_AsUTF8(s): "input");
  Py_XDECREF(s);
  return -1;
}

static PyObject* get_max_param_change(PyObject* self, void* xdata) {
  auto cpp = ThisPtr(self); if (!cpp) return nullptr;
  return Clif_PyObjFrom(cpp->max_param_change, {});
}

static int set_max_param_change(PyObject* self, PyObject* value, void* xdata) {
  if (value == nullptr) {
    PyErr_SetString(PyExc_TypeError, "Cannot delete the max_param_change attribute");
    return -1;
  }
  auto cpp = ThisPtr(self); if (!cpp) return -1;
  if (Clif_PyObjAs(value, &cpp->max_param_change)) return 0;
  PyObject* s = PyObject_Repr(value);
  PyErr_Format(PyExc_ValueError, "%s is not valid for max_param_change:float", s? PyUnicode_AsUTF8(s): "input");
  Py_XDECREF(s);
  return -1;
}

static PyObject* get_l2_regularize_factor(PyObject* self, void* xdata) {
  auto cpp = ThisPtr(self); if (!cpp) return nullptr;
  return Clif_PyObjFrom(cpp->l2_regularize_factor, {});
}

static int set_l2_regularize_factor(PyObject* self, PyObject* value, void* xdata) {
  if (value == nullptr) {
    PyErr_SetString(PyExc_TypeError, "Cannot delete the l2_regularize_factor attribute");
    return -1;
  }
  auto cpp = ThisPtr(self); if (!cpp) return -1;
  if (Clif_PyObjAs(value, &cpp->l2_regularize_factor)) return 0;
  PyObject* s = PyObject_Repr(value);
  PyErr_Format(PyExc_ValueError, "%s is not valid for l2_regularize_factor:float", s? PyUnicode_AsUTF8(s): "input");
  Py_XDECREF(s);
  return -1;
}

static PyObject* get_backstitch_training_scale(PyObject* self, void* xdata) {
  auto cpp = ThisPtr(self); if (!cpp) return nullptr;
  return Clif_PyObjFrom(cpp->backstitch_training_scale, {});
}

static int set_backstitch_training_scale(PyObject* self, PyObject* value, void* xdata) {
  if (value == nullptr) {
    PyErr_SetString(PyExc_TypeError, "Cannot delete the backstitch_training_scale attribute");
    return -1;
  }
  auto cpp = ThisPtr(self); if (!cpp) return -1;
  if (Clif_PyObjAs(value, &cpp->backstitch_training_scale)) return 0;
  PyObject* s = PyObject_Repr(value);
  PyErr_Format(PyExc_ValueError, "%s is not valid for backstitch_training_scale:float", s? PyUnicode_AsUTF8(s): "input");
  Py_XDECREF(s);
  return -1;
}

static PyObject* get_backstitch_training_interval(PyObject* self, void* xdata) {
  auto cpp = ThisPtr(self); if (!cpp) return nullptr;
  return Clif_PyObjFrom(cpp->backstitch_training_interval, {});
}

static int set_backstitch_training_interval(PyObject* self, PyObject* value, void* xdata) {
  if (value == nullptr) {
    PyErr_SetString(PyExc_TypeError, "Cannot delete the backstitch_training_interval attribute");
    return -1;
  }
  auto cpp = ThisPtr(self); if (!cpp) return -1;
  if (Clif_PyObjAs(value, &cpp->backstitch_training_interval)) return 0;
  PyObject* s = PyObject_Repr(value);
  PyErr_Format(PyExc_ValueError, "%s is not valid for backstitch_training_interval:int", s? PyUnicode_AsUTF8(s): "input");
  Py_XDECREF(s);
  return -1;
}

// register(opts:OptionsItf)
static PyObject* wrapRegister_as_register(PyObject* self, PyObject* args, PyObject* kw) {
  PyObject* a[1];
  char* names[] = {
      C("opts"),
      nullptr
  };
  if (!PyArg_ParseTupleAndKeywords(args, kw, "O:register", names, &a[0])) return nullptr;
  ::kaldi::OptionsItf * arg1;
  if (!Clif_PyObjAs(a[0], &arg1)) return ArgError("register", names[0], "::kaldi::OptionsItf *", a[0]);
  // Call actual C++ method.
  ::kaldi::rnnlm::RnnlmCoreTrainerOptions* c = ThisPtr(self);
  if (!c) return nullptr;
  Py_INCREF(args);
  Py_XINCREF(kw);
  PyThreadState* _save;
  Py_UNBLOCK_THREADS
  PyObject* err_type = nullptr;
  string err_msg{"C++ exception"};
  try {
    c->Register(arg1);
  } catch(const std::exception& e) {
    err_type = PyExc_RuntimeError;
    err_msg += string(": ") + e.what();
  } catch (...) {
    err_type = PyExc_RuntimeError;
  }
  Py_BLOCK_THREADS
  Py_DECREF(args);
  Py_XDECREF(kw);
  if (err_type) {
    PyErr_SetString(err_type, err_msg.c_str());
    return nullptr;
  }
  Py_RETURN_NONE;
}

static PyGetSetDef Properties[] = {
  {C("print_interval"), get_print_interval, set_print_interval, C("The log printing interval (in terms of #minibatches).")},
  {C("momentum"), get_momentum, set_momentum, C("Momentum constant (help stabilize training updates), e.g. 0.9.\n\nWe automatically multiply the learning rate by (1-momentum) so that the\n'effective' learning rate is the same as  before (because momentum would\nnormally increase the effective learning rate by 1/(1-momentum)).")},
  {C("max_param_change"), get_max_param_change, set_max_param_change, C("The maximum change in model parameters allowed per minibatch.\n\nThis is measured in Euclidean norm. Change will be clipped to this value.")},
  {C("l2_regularize_factor"), get_l2_regularize_factor, set_l2_regularize_factor, C("Factor that affects the strength of l2 regularization.\n\nThis affects the strength of l2 regularization on model parameters. It\nwill be multiplied by the component-level l2-regularize values and can\nbe used to correct for effects related to parallelization by model\naveraging.")},
  {C("backstitch_training_scale"), get_backstitch_training_scale, set_backstitch_training_scale, C("Backstitch training factor (alpha).\n\nIf 0 then in the normal training mode.")},
  {C("backstitch_training_interval"), get_backstitch_training_interval, set_backstitch_training_interval, C("Backstitch training interval (n).\n\nDo backstitch training with the specified interval of minibatches.")},
  {}
};

static PyMethodDef Methods[] = {
  {C("register"), (PyCFunction)wrapRegister_as_register, METH_VARARGS | METH_KEYWORDS, C("register(opts:OptionsItf)\n\nRegisters options with an object implementing the options interface.\n\nArgs:\n  opts (OptionsItf): An object implementing the options interface.\n    Typically a command-line option parser.")},
  {}
};

// RnnlmCoreTrainerOptions __init__
static int _ctor(PyObject* self, PyObject* args, PyObject* kw);

// RnnlmCoreTrainerOptions __new__
static PyObject* _new(PyTypeObject* type, Py_ssize_t nitems);

// RnnlmCoreTrainerOptions __del__
static void _del(void* self) {
  delete reinterpret_cast<wrapper*>(self);
}

PyTypeObject wrapper_Type = {
  PyVarObject_HEAD_INIT(&PyType_Type, 0)
  "_rnnlm_core_training.RnnlmCoreTrainerOptions", // tp_name
  sizeof(wrapper),                     // tp_basicsize
  0,                                   // tp_itemsize
  nullptr,                             // tp_dealloc
  nullptr,                             // tp_print
  nullptr,                             // tp_getattr
  nullptr,                             // tp_setattr
  nullptr,                             // tp_compare
  nullptr,                             // tp_repr
  nullptr,                             // tp_as_number
  nullptr,                             // tp_as_sequence
  nullptr,                             // tp_as_mapping
  nullptr,                             // tp_hash
  nullptr,                             // tp_call
  nullptr,                             // tp_str
  nullptr,                             // tp_getattro
  nullptr,                             // tp_setattro
  nullptr,                             // tp_as_buffer
  Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE, // tp_flags
  "Options for core RNNLM training.\n\nThese are related to the core RNNLM training, i.e. training the actual\nneural net for the RNNLM (when the word embeddings are given).", // tp_doc
  nullptr,                             // tp_traverse
  nullptr,                             // tp_clear
  nullptr,                             // tp_richcompare
  0,                                   // tp_weaklistoffset
  nullptr,                             // tp_iter
  nullptr,                             // tp_iternext
  Methods,                             // tp_methods
  nullptr,                             // tp_members
  Properties,                          // tp_getset
  nullptr,                             // tp_base
  nullptr,                             // tp_dict
  nullptr,                             // tp_descr_get
  nullptr,                             // tp_descr_set
  0,                                   // tp_dictoffset
  _ctor,                               // tp_init
  _new,                                // tp_alloc
  PyType_GenericNew,                   // tp_new
  _del,                                // tp_free
  nullptr,                             // tp_is_gc
  nullptr,                             // tp_bases
  nullptr,                             // tp_mro
  nullptr,                             // tp_cache
  nullptr,                             // tp_subclasses
  nullptr,                             // tp_weaklist
  nullptr,                             // tp_del
  0,                                   // tp_version_tag
};

static int _ctor(PyObject* self, PyObject* args, PyObject* kw) {
  if ((args && PyTuple_GET_SIZE(args) != 0) || (kw && PyDict_Size(kw) != 0)) {
    PyErr_SetString(PyExc_TypeError, "RnnlmCoreTrainerOptions takes no arguments");
    return -1;
  }
  reinterpret_cast<wrapper*>(self)->cpp = ::clif::MakeShared<::kaldi::rnnlm::RnnlmCoreTrainerOptions>();
  return 0;
}

static PyObject* _new(PyTypeObject* type, Py_ssize_t nitems) {
  assert(nitems == 0);
  PyObject* self = reinterpret_cast<PyObject*>(new wrapper);
  return PyObject_Init(self, &wrapper_Type);
}

static ::kaldi::rnnlm::RnnlmCoreTrainerOptions* ThisPtr(PyObject* py) {
  if (Py_TYPE(py) == &wrapper_Type) {
    return ::clif::python::Get(reinterpret_cast<wrapper*>(py)->cpp);
  }
  PyObject* base = PyObject_CallMethod(py, C("as_kaldi_rnnlm_RnnlmCoreTrainerOptions"), nullptr);
  if (base) {
    if (PyCapsule_CheckExact(base)) {
      void* p = PyCapsule_GetPointer(base, C("::kaldi::rnnlm::RnnlmCoreTrainerOptions"));
      if (!PyErr_Occurred()) {
        ::kaldi::rnnlm::RnnlmCoreTrainerOptions* c = static_cast<::kaldi::rnnlm::RnnlmCoreTrainerOptions*>(p);
        Py_DECREF(base);
        return c;
      }
    }
    Py_DECREF(base);
  }
  if (PyObject_IsInstance(py, reinterpret_cast<PyObject*>(&wrapper_Type))) {
    if (!base) {
      PyErr_Clear();
      return ::clif::python::Get(reinterpret_cast<wrapper*>(py)->cpp);
    }
    PyErr_Format(PyExc_ValueError, "can't convert %s %s to ::kaldi::rnnlm::RnnlmCoreTrainerOptions*", ClassName(py), ClassType(py));
  } else {
    PyErr_Format(PyExc_TypeError, "expecting %s instance, got %s %s", wrapper_Type.tp_name, ClassName(py), ClassType(py));
  }
  return nullptr;
}
}  // namespace pyRnnlmCoreTrainerOptions

namespace pyRnnlmCoreTrainer {

struct wrapper {
  PyObject_HEAD
  ::clif::Instance<::kaldi::rnnlm::RnnlmCoreTrainer> cpp;
};
static ::kaldi::rnnlm::RnnlmCoreTrainer* ThisPtr(PyObject*);

// __init__(config:RnnlmCoreTrainerOptions, objective_config:RnnlmObjectiveOptions, nnet:Nnet)
static PyObject* wrapRnnlmCoreTrainer_as___init__(PyObject* self, PyObject* args, PyObject* kw) {
  PyObject* a[3];
  char* names[] = {
      C("config"),
      C("objective_config"),
      C("nnet"),
      nullptr
  };
  if (!PyArg_ParseTupleAndKeywords(args, kw, "OOO:__init__", names, &a[0], &a[1], &a[2])) return nullptr;
  ::kaldi::rnnlm::RnnlmCoreTrainerOptions* arg1;
  if (!Clif_PyObjAs(a[0], &arg1)) return ArgError("__init__", names[0], "::kaldi::rnnlm::RnnlmCoreTrainerOptions", a[0]);
  ::kaldi::rnnlm::RnnlmObjectiveOptions* arg2;
  if (!Clif_PyObjAs(a[1], &arg2)) return ArgError("__init__", names[1], "::kaldi::rnnlm::RnnlmObjectiveOptions", a[1]);
  ::kaldi::nnet3::Nnet * arg3;
  if (!Clif_PyObjAs(a[2], &arg3)) return ArgError("__init__", names[2], "::kaldi::nnet3::Nnet *", a[2]);
  // Call actual C++ method.
  Py_INCREF(args);
  Py_XINCREF(kw);
  PyThreadState* _save;
  Py_UNBLOCK_THREADS
  PyObject* err_type = nullptr;
  string err_msg{"C++ exception"};
  try {
    reinterpret_cast<wrapper*>(self)->cpp = ::clif::MakeShared<::kaldi::rnnlm::RnnlmCoreTrainer>(*arg1, *arg2, arg3);
  } catch(const std::exception& e) {
    err_type = PyExc_RuntimeError;
    err_msg += string(": ") + e.what();
  } catch (...) {
    err_type = PyExc_RuntimeError;
  }
  Py_BLOCK_THREADS
  Py_DECREF(args);
  Py_XDECREF(kw);
  if (err_type) {
    PyErr_SetString(err_type, err_msg.c_str());
    return nullptr;
  }
  Py_RETURN_NONE;
}

// train(minibatch:RnnlmExample, derived:RnnlmExampleDerived, word_embedding:CuMatrixBase, word_embedding_deriv:CuMatrixBase)
static PyObject* wrapTrain_as_train(PyObject* self, PyObject* args, PyObject* kw) {
  PyObject* a[4];
  char* names[] = {
      C("minibatch"),
      C("derived"),
      C("word_embedding"),
      C("word_embedding_deriv"),
      nullptr
  };
  if (!PyArg_ParseTupleAndKeywords(args, kw, "OOOO:train", names, &a[0], &a[1], &a[2], &a[3])) return nullptr;
  ::kaldi::rnnlm::RnnlmExample* arg1;
  if (!Clif_PyObjAs(a[0], &arg1)) return ArgError("train", names[0], "::kaldi::rnnlm::RnnlmExample", a[0]);
  ::kaldi::rnnlm::RnnlmExampleDerived* arg2;
  if (!Clif_PyObjAs(a[1], &arg2)) return ArgError("train", names[1], "::kaldi::rnnlm::RnnlmExampleDerived", a[1]);
  ::kaldi::CuMatrixBase<float>* arg3;
  if (!Clif_PyObjAs(a[2], &arg3)) return ArgError("train", names[2], "::kaldi::CuMatrixBase<float>", a[2]);
  ::kaldi::CuMatrixBase<float> * arg4;
  if (!Clif_PyObjAs(a[3], &arg4)) return ArgError("train", names[3], "::kaldi::CuMatrixBase<float> *", a[3]);
  // Call actual C++ method.
  ::kaldi::rnnlm::RnnlmCoreTrainer* c = ThisPtr(self);
  if (!c) return nullptr;
  Py_INCREF(args);
  Py_XINCREF(kw);
  PyThreadState* _save;
  Py_UNBLOCK_THREADS
  PyObject* err_type = nullptr;
  string err_msg{"C++ exception"};
  try {
    c->Train(*arg1, *arg2, *arg3, arg4);
  } catch(const std::exception& e) {
    err_type = PyExc_RuntimeError;
    err_msg += string(": ") + e.what();
  } catch (...) {
    err_type = PyExc_RuntimeError;
  }
  Py_BLOCK_THREADS
  Py_DECREF(args);
  Py_XDECREF(kw);
  if (err_type) {
    PyErr_SetString(err_type, err_msg.c_str());
    return nullptr;
  }
  Py_RETURN_NONE;
}

// train_backstitch(is_backstitch_step1:bool, minibatch:RnnlmExample, derived:RnnlmExampleDerived, word_embedding:CuMatrixBase, word_embedding_deriv:CuMatrixBase)
static PyObject* wrapTrainBackstitch_as_train_backstitch(PyObject* self, PyObject* args, PyObject* kw) {
  PyObject* a[5];
  char* names[] = {
      C("is_backstitch_step1"),
      C("minibatch"),
      C("derived"),
      C("word_embedding"),
      C("word_embedding_deriv"),
      nullptr
  };
  if (!PyArg_ParseTupleAndKeywords(args, kw, "OOOOO:train_backstitch", names, &a[0], &a[1], &a[2], &a[3], &a[4])) return nullptr;
  bool arg1;
  if (!Clif_PyObjAs(a[0], &arg1)) return ArgError("train_backstitch", names[0], "bool", a[0]);
  ::kaldi::rnnlm::RnnlmExample* arg2;
  if (!Clif_PyObjAs(a[1], &arg2)) return ArgError("train_backstitch", names[1], "::kaldi::rnnlm::RnnlmExample", a[1]);
  ::kaldi::rnnlm::RnnlmExampleDerived* arg3;
  if (!Clif_PyObjAs(a[2], &arg3)) return ArgError("train_backstitch", names[2], "::kaldi::rnnlm::RnnlmExampleDerived", a[2]);
  ::kaldi::CuMatrixBase<float>* arg4;
  if (!Clif_PyObjAs(a[3], &arg4)) return ArgError("train_backstitch", names[3], "::kaldi::CuMatrixBase<float>", a[3]);
  ::kaldi::CuMatrixBase<float> * arg5;
  if (!Clif_PyObjAs(a[4], &arg5)) return ArgError("train_backstitch", names[4], "::kaldi::CuMatrixBase<float> *", a[4]);
  // Call actual C++ method.
  ::kaldi::rnnlm::RnnlmCoreTrainer* c = ThisPtr(self);
  if (!c) return nullptr;
  Py_INCREF(args);
  Py_XINCREF(kw);
  PyThreadState* _save;
  Py_UNBLOCK_THREADS
  PyObject* err_type = nullptr;
  string err_msg{"C++ exception"};
  try {
    c->TrainBackstitch(std::move(arg1), *arg2, *arg3, *arg4, arg5);
  } catch(const std::exception& e) {
    err_type = PyExc_RuntimeError;
    err_msg += string(": ") + e.what();
  } catch (...) {
    err_type = PyExc_RuntimeError;
  }
  Py_BLOCK_THREADS
  Py_DECREF(args);
  Py_XDECREF(kw);
  if (err_type) {
    PyErr_SetString(err_type, err_msg.c_str());
    return nullptr;
  }
  Py_RETURN_NONE;
}

// print_max_change_stats()
static PyObject* wrapPrintMaxChangeStats_as_print_max_change_stats(PyObject* self) {
  // Call actual C++ method.
  ::kaldi::rnnlm::RnnlmCoreTrainer* c = ThisPtr(self);
  if (!c) return nullptr;
  PyThreadState* _save;
  Py_UNBLOCK_THREADS
  PyObject* err_type = nullptr;
  string err_msg{"C++ exception"};
  try {
    c->PrintMaxChangeStats();
  } catch(const std::exception& e) {
    err_type = PyExc_RuntimeError;
    err_msg += string(": ") + e.what();
  } catch (...) {
    err_type = PyExc_RuntimeError;
  }
  Py_BLOCK_THREADS
  if (err_type) {
    PyErr_SetString(err_type, err_msg.c_str());
    return nullptr;
  }
  Py_RETURN_NONE;
}

static PyMethodDef Methods[] = {
  {C("__init__"), (PyCFunction)wrapRnnlmCoreTrainer_as___init__, METH_VARARGS | METH_KEYWORDS, C("__init__(config:RnnlmCoreTrainerOptions, objective_config:RnnlmObjectiveOptions, nnet:Nnet)\n  Calls C++ function\n  void ::kaldi::rnnlm::RnnlmCoreTrainer::RnnlmCoreTrainer(::kaldi::rnnlm::RnnlmCoreTrainerOptions, ::kaldi::rnnlm::RnnlmObjectiveOptions, ::kaldi::nnet3::Nnet *)")},
  {C("train"), (PyCFunction)wrapTrain_as_train, METH_VARARGS | METH_KEYWORDS, C("train(minibatch:RnnlmExample, derived:RnnlmExampleDerived, word_embedding:CuMatrixBase, word_embedding_deriv:CuMatrixBase)\n\nDo training for one minibatch.\n\nArgs:\n  minibatch (RnnlmExample): The RNNLM minibatch to train on, containing\n    a number of parallel word sequences.  It will not necessarily\n    contain words with the 'original' numbering, it will in most\n    circumstances contain just the ones we used; see\n    :meth:`renumber_rnnlm_example`.\n  derived (RnnlmExampleDerived): Derived quantities of the minibatch,\n    pre-computed by calling :meth:`get_rnnlm_example_derived` with\n    suitable arguments.\n  word_embedding (CuMatrixBase): The matrix giving the embedding of\n    words, of dimension `minibatch.vocab_size` by the embedding\n    dimension. The numbering of the words does not have to be the\n    'real' numbering of words, it can consist of words renumbered by\n    :meth:`renumber_rnnlm_example`; it just has to be consistent with\n    the word-ids present in 'minibatch'.\n  word_embedding_deriv (CuMatrixBase): If not None, the derivative of\n    the objective function w.r.t. the word embedding will be *added* to\n    this location; it must have the same dimension as 'word_embedding'.")},
  {C("train_backstitch"), (PyCFunction)wrapTrainBackstitch_as_train_backstitch, METH_VARARGS | METH_KEYWORDS, C("train_backstitch(is_backstitch_step1:bool, minibatch:RnnlmExample, derived:RnnlmExampleDerived, word_embedding:CuMatrixBase, word_embedding_deriv:CuMatrixBase)\n\nDo backstitch training for one minibatch.\n\nDepending on whether is_backstitch_step1 is true, It could be either\nthe first (backward) step, or the second (forward) step of backstitch.\n\nArgs:\n  is_backstitch_step1 (bool): If true update stats otherwise not.\n  minibatch (RnnlmExample): The RNNLM minibatch to train on, containing\n    a number of parallel word sequences.  It will not necessarily\n    contain words with the 'original' numbering, it will in most\n    circumstances contain just the ones we used; see\n    :meth:`renumber_rnnlm_example`.\n  derived (RnnlmExampleDerived): Derived quantities of the minibatch,\n    pre-computed by calling :meth:`get_rnnlm_example_derived` with\n    suitable arguments.\n  word_embedding (CuMatrixBase): The matrix giving the embedding of\n    words, of dimension `minibatch.vocab_size` by the embedding\n    dimension. The numbering of the words does not have to be the\n    'real' numbering of words, it can consist of words renumbered by\n    :meth:`renumber_rnnlm_example`; it just has to be consistent with\n    the word-ids present in 'minibatch'.\n  word_embedding_deriv (CuMatrixBase): If not None, the derivative of\n    the objective function w.r.t. the word embedding will be *added* to\n    this location; it must have the same dimension as 'word_embedding'.")},
  {C("print_max_change_stats"), (PyCFunction)wrapPrintMaxChangeStats_as_print_max_change_stats, METH_NOARGS, C("print_max_change_stats()\n\nPrints out the max-change stats (if nonzero).\n\nThis is the percentage of time that per-component max-change and global\nmax-change were enforced.")},
  {}
};

// RnnlmCoreTrainer __init__
static int _ctor(PyObject* self, PyObject* args, PyObject* kw);

// RnnlmCoreTrainer __new__
static PyObject* _new(PyTypeObject* type, Py_ssize_t nitems);

// RnnlmCoreTrainer __del__
static void _dtor(PyObject* self) {
  Py_BEGIN_ALLOW_THREADS
  reinterpret_cast<wrapper*>(self)->cpp.Destruct();
  Py_END_ALLOW_THREADS
  Py_TYPE(self)->tp_free(self);
}
static void _del(void* self) {
  delete reinterpret_cast<wrapper*>(self);
}

PyTypeObject wrapper_Type = {
  PyVarObject_HEAD_INIT(&PyType_Type, 0)
  "_rnnlm_core_training.RnnlmCoreTrainer", // tp_name
  sizeof(wrapper),                     // tp_basicsize
  0,                                   // tp_itemsize
  _dtor,                               // tp_dealloc
  nullptr,                             // tp_print
  nullptr,                             // tp_getattr
  nullptr,                             // tp_setattr
  nullptr,                             // tp_compare
  nullptr,                             // tp_repr
  nullptr,                             // tp_as_number
  nullptr,                             // tp_as_sequence
  nullptr,                             // tp_as_mapping
  nullptr,                             // tp_hash
  nullptr,                             // tp_call
  nullptr,                             // tp_str
  nullptr,                             // tp_getattro
  nullptr,                             // tp_setattro
  nullptr,                             // tp_as_buffer
  Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE, // tp_flags
  "Core RNNLM trainer.\n\nThis class does the core part of the training of the RNNLM; the\nword embeddings are supplied to this class for each minibatch and\nwhile this class can compute objective function derivatives w.r.t.\nthese embeddings, it is not responsible for updating them.\n\nArgs:\n  config (RnnlmCoreTrainerOptions): Options for core RNNLM training.\n  objective_config (RnnlmObjectiveOptions): Options for RNNLM objective.\n  nnet (Nnet): The neural network that is to be trained. It will be\n    modified each time you call :meth:`train`.", // tp_doc
  nullptr,                             // tp_traverse
  nullptr,                             // tp_clear
  nullptr,                             // tp_richcompare
  0,                                   // tp_weaklistoffset
  nullptr,                             // tp_iter
  nullptr,                             // tp_iternext
  Methods,                             // tp_methods
  nullptr,                             // tp_members
  nullptr,                             // tp_getset
  nullptr,                             // tp_base
  nullptr,                             // tp_dict
  nullptr,                             // tp_descr_get
  nullptr,                             // tp_descr_set
  0,                                   // tp_dictoffset
  _ctor,                               // tp_init
  _new,                                // tp_alloc
  PyType_GenericNew,                   // tp_new
  _del,                                // tp_free
  nullptr,                             // tp_is_gc
  nullptr,                             // tp_bases
  nullptr,                             // tp_mro
  nullptr,                             // tp_cache
  nullptr,                             // tp_subclasses
  nullptr,                             // tp_weaklist
  nullptr,                             // tp_del
  0,                                   // tp_version_tag
};

static int _ctor(PyObject* self, PyObject* args, PyObject* kw) {
  PyObject* init = wrapRnnlmCoreTrainer_as___init__(self, args, kw);
  Py_XDECREF(init);
  return init? 0: -1;
}

static PyObject* _new(PyTypeObject* type, Py_ssize_t nitems) {
  assert(nitems == 0);
  PyObject* self = reinterpret_cast<PyObject*>(new wrapper);
  return PyObject_Init(self, &wrapper_Type);
}

static ::kaldi::rnnlm::RnnlmCoreTrainer* ThisPtr(PyObject* py) {
  if (Py_TYPE(py) == &wrapper_Type) {
    return ::clif::python::Get(reinterpret_cast<wrapper*>(py)->cpp);
  }
  PyObject* base = PyObject_CallMethod(py, C("as_kaldi_rnnlm_RnnlmCoreTrainer"), nullptr);
  if (base) {
    if (PyCapsule_CheckExact(base)) {
      void* p = PyCapsule_GetPointer(base, C("::kaldi::rnnlm::RnnlmCoreTrainer"));
      if (!PyErr_Occurred()) {
        ::kaldi::rnnlm::RnnlmCoreTrainer* c = static_cast<::kaldi::rnnlm::RnnlmCoreTrainer*>(p);
        Py_DECREF(base);
        return c;
      }
    }
    Py_DECREF(base);
  }
  if (PyObject_IsInstance(py, reinterpret_cast<PyObject*>(&wrapper_Type))) {
    if (!base) {
      PyErr_Clear();
      return ::clif::python::Get(reinterpret_cast<wrapper*>(py)->cpp);
    }
    PyErr_Format(PyExc_ValueError, "can't convert %s %s to ::kaldi::rnnlm::RnnlmCoreTrainer*", ClassName(py), ClassType(py));
  } else {
    PyErr_Format(PyExc_TypeError, "expecting %s instance, got %s %s", wrapper_Type.tp_name, ClassName(py), ClassType(py));
  }
  return nullptr;
}
}  // namespace pyRnnlmCoreTrainer


// Initialize module

bool Ready() {
  if (PyType_Ready(&pyRnnlmCoreTrainerOptions::wrapper_Type) < 0) return false;
  Py_INCREF(&pyRnnlmCoreTrainerOptions::wrapper_Type);  // For PyModule_AddObject to steal.
  if (PyType_Ready(&pyRnnlmCoreTrainer::wrapper_Type) < 0) return false;
  Py_INCREF(&pyRnnlmCoreTrainer::wrapper_Type);  // For PyModule_AddObject to steal.
  return true;
}

static struct PyModuleDef Module = {
  PyModuleDef_HEAD_INIT,
  "_rnnlm_core_training",  // module name
  "CLIF-generated module for rnnlm/rnnlm-core-training.h", // module doc
  -1,  // module keeps state in global variables
  nullptr
};

PyObject* Init() {
  PyObject* module = PyModule_Create(&Module);
  if (!module) return nullptr;
  if (PyObject* m = PyImport_ImportModule("_options_itf")) Py_DECREF(m);
  else goto err;
  if (PyObject* m = PyImport_ImportModule("_cu_matrix")) Py_DECREF(m);
  else goto err;
  if (PyObject* m = PyImport_ImportModule("_nnet_nnet")) Py_DECREF(m);
  else goto err;
  if (PyObject* m = PyImport_ImportModule("_rnnlm_example")) Py_DECREF(m);
  else goto err;
  if (PyObject* m = PyImport_ImportModule("_rnnlm_example_utils")) Py_DECREF(m);
  else goto err;
  PyEval_InitThreads();
  if (PyModule_AddObject(module, "RnnlmCoreTrainerOptions", reinterpret_cast<PyObject*>(&pyRnnlmCoreTrainerOptions::wrapper_Type)) < 0) goto err;
  if (PyModule_AddObject(module, "RnnlmCoreTrainer", reinterpret_cast<PyObject*>(&pyRnnlmCoreTrainer::wrapper_Type)) < 0) goto err;
  return module;
err:
  Py_DECREF(module);
  return nullptr;
}

}  // namespace __rnnlm__core__training_clifwrap

namespace kaldi { namespace rnnlm {
using namespace ::clif;
using ::clif::Clif_PyObjAs;
using ::clif::Clif_PyObjFrom;

// RnnlmCoreTrainer to/from ::kaldi::rnnlm::RnnlmCoreTrainer conversion

bool Clif_PyObjAs(PyObject* py, ::kaldi::rnnlm::RnnlmCoreTrainer** c) {
  assert(c != nullptr);
  if (Py_None == py) {
    *c = nullptr;
    return true;
  }
  ::kaldi::rnnlm::RnnlmCoreTrainer* cpp = __rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::ThisPtr(py);
  if (cpp == nullptr) return false;
  *c = cpp;
  return true;
}

bool Clif_PyObjAs(PyObject* py, std::shared_ptr<::kaldi::rnnlm::RnnlmCoreTrainer>* c) {
  assert(c != nullptr);
  ::kaldi::rnnlm::RnnlmCoreTrainer* cpp = __rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::ThisPtr(py);
  if (cpp == nullptr) return false;
  *c = ::clif::MakeStdShared(reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::wrapper*>(py)->cpp, cpp);
  return true;
}

bool Clif_PyObjAs(PyObject* py, std::unique_ptr<::kaldi::rnnlm::RnnlmCoreTrainer>* c) {
  assert(c != nullptr);
  ::kaldi::rnnlm::RnnlmCoreTrainer* cpp = __rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::ThisPtr(py);
  if (cpp == nullptr) return false;
  if (!reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::wrapper*>(py)->cpp.Detach()) {
    PyErr_SetString(PyExc_ValueError, "Cannot convert RnnlmCoreTrainer instance to std::unique_ptr.");
    return false;
  }
  c->reset(cpp);
  return true;
}

PyObject* Clif_PyObjFrom(::kaldi::rnnlm::RnnlmCoreTrainer* c, py::PostConv unused) {
  if (c == nullptr) Py_RETURN_NONE;
  PyObject* py = PyType_GenericNew(&__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::wrapper_Type, NULL, NULL);
  reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::wrapper*>(py)->cpp = ::clif::Instance<::kaldi::rnnlm::RnnlmCoreTrainer>(c, ::clif::UnOwnedResource());
  return py;
}

PyObject* Clif_PyObjFrom(std::shared_ptr<::kaldi::rnnlm::RnnlmCoreTrainer> c, py::PostConv unused) {
  if (c == nullptr) Py_RETURN_NONE;
  PyObject* py = PyType_GenericNew(&__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::wrapper_Type, NULL, NULL);
  reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::wrapper*>(py)->cpp = ::clif::Instance<::kaldi::rnnlm::RnnlmCoreTrainer>(c);
  return py;
}

PyObject* Clif_PyObjFrom(std::unique_ptr<::kaldi::rnnlm::RnnlmCoreTrainer> c, py::PostConv unused) {
  if (c == nullptr) Py_RETURN_NONE;
  PyObject* py = PyType_GenericNew(&__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::wrapper_Type, NULL, NULL);
  reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainer::wrapper*>(py)->cpp = ::clif::Instance<::kaldi::rnnlm::RnnlmCoreTrainer>(std::move(c));
  return py;
}

// RnnlmCoreTrainerOptions to/from ::kaldi::rnnlm::RnnlmCoreTrainerOptions conversion

bool Clif_PyObjAs(PyObject* py, ::kaldi::rnnlm::RnnlmCoreTrainerOptions** c) {
  assert(c != nullptr);
  if (Py_None == py) {
    *c = nullptr;
    return true;
  }
  ::kaldi::rnnlm::RnnlmCoreTrainerOptions* cpp = __rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::ThisPtr(py);
  if (cpp == nullptr) return false;
  *c = cpp;
  return true;
}

bool Clif_PyObjAs(PyObject* py, std::shared_ptr<::kaldi::rnnlm::RnnlmCoreTrainerOptions>* c) {
  assert(c != nullptr);
  ::kaldi::rnnlm::RnnlmCoreTrainerOptions* cpp = __rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::ThisPtr(py);
  if (cpp == nullptr) return false;
  *c = ::clif::MakeStdShared(reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper*>(py)->cpp, cpp);
  return true;
}

bool Clif_PyObjAs(PyObject* py, std::unique_ptr<::kaldi::rnnlm::RnnlmCoreTrainerOptions>* c) {
  assert(c != nullptr);
  ::kaldi::rnnlm::RnnlmCoreTrainerOptions* cpp = __rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::ThisPtr(py);
  if (cpp == nullptr) return false;
  if (!reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper*>(py)->cpp.Detach()) {
    PyErr_SetString(PyExc_ValueError, "Cannot convert RnnlmCoreTrainerOptions instance to std::unique_ptr.");
    return false;
  }
  c->reset(cpp);
  return true;
}

bool Clif_PyObjAs(PyObject* py, ::kaldi::rnnlm::RnnlmCoreTrainerOptions* c) {
  assert(c != nullptr);
  ::kaldi::rnnlm::RnnlmCoreTrainerOptions* cpp = __rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::ThisPtr(py);
  if (cpp == nullptr) return false;
  *c = *cpp;
  return true;
}

bool Clif_PyObjAs(PyObject* py, ::gtl::optional<::kaldi::rnnlm::RnnlmCoreTrainerOptions>* c) {
  assert(c != nullptr);
  ::kaldi::rnnlm::RnnlmCoreTrainerOptions* cpp = __rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::ThisPtr(py);
  if (cpp == nullptr) return false;
  *c = *cpp;
  return true;
}

PyObject* Clif_PyObjFrom(::kaldi::rnnlm::RnnlmCoreTrainerOptions* c, py::PostConv unused) {
  if (c == nullptr) Py_RETURN_NONE;
  PyObject* py = PyType_GenericNew(&__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper_Type, NULL, NULL);
  reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper*>(py)->cpp = ::clif::Instance<::kaldi::rnnlm::RnnlmCoreTrainerOptions>(c, ::clif::UnOwnedResource());
  return py;
}

PyObject* Clif_PyObjFrom(std::shared_ptr<::kaldi::rnnlm::RnnlmCoreTrainerOptions> c, py::PostConv unused) {
  if (c == nullptr) Py_RETURN_NONE;
  PyObject* py = PyType_GenericNew(&__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper_Type, NULL, NULL);
  reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper*>(py)->cpp = ::clif::Instance<::kaldi::rnnlm::RnnlmCoreTrainerOptions>(c);
  return py;
}

PyObject* Clif_PyObjFrom(std::unique_ptr<::kaldi::rnnlm::RnnlmCoreTrainerOptions> c, py::PostConv unused) {
  if (c == nullptr) Py_RETURN_NONE;
  PyObject* py = PyType_GenericNew(&__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper_Type, NULL, NULL);
  reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper*>(py)->cpp = ::clif::Instance<::kaldi::rnnlm::RnnlmCoreTrainerOptions>(std::move(c));
  return py;
}

PyObject* Clif_PyObjFrom(const ::kaldi::rnnlm::RnnlmCoreTrainerOptions& c, py::PostConv unused) {
  PyObject* py = PyType_GenericNew(&__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper_Type, NULL, NULL);
  reinterpret_cast<__rnnlm__core__training_clifwrap::pyRnnlmCoreTrainerOptions::wrapper*>(py)->cpp = ::clif::MakeShared<::kaldi::rnnlm::RnnlmCoreTrainerOptions>(c);
  return py;
}

} }  // namespace kaldi::rnnlm
